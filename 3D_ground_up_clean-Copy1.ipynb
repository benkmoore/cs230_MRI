{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import scipy as scipy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.engine import Layer\n",
    "\n",
    "from keras.layers import Input, Dense, Conv1D, Conv2D, MaxPooling2D, Deconvolution2D, UpSampling2D, Reshape, Flatten, ZeroPadding2D, BatchNormalization, Lambda, Dropout, Activation\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#from vis.utils import utils\n",
    "#from vis.visualization import visualize_saliency\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import nibabel as nib\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "theano.config.opennp = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters (Modify as needed)\n",
    "img_size_x = 110\n",
    "img_size_y = 110\n",
    "img_size_z = 110\n",
    "\n",
    "batch_size = 10\n",
    "classes = 2\n",
    "epochs = 50\n",
    "lr = 27*1e-6\n",
    "\n",
    "early_stopping_patience = 20\n",
    "class_names = ['NC', 'AD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_clean():\n",
    "    AD_directory = \"/home/ubuntu/project/Data/AD_clean/\"\n",
    "    NC_directory = \"/home/ubuntu/project/Data/NC_clean/\"\n",
    "    \n",
    "    AD_list = os.listdir(AD_directory)\n",
    "    NC_list = os.listdir(NC_directory)\n",
    "    \n",
    "\n",
    "    All_directory = \"/home/ubuntu/project/Data/AD_NC_Clean/\"\n",
    "\n",
    "    X = np.zeros((111,img_size_x,img_size_y,img_size_z,1))\n",
    "    Y = np.zeros(111)\n",
    "    \n",
    "    l = os.listdir(All_directory)\n",
    "    random.shuffle(l)\n",
    "   \n",
    "    \n",
    "    objindex = 0\n",
    "    for i, filename in enumerate(l):\n",
    "        if (filename.startswith('.')):\n",
    "            print (\"hidden file\")\n",
    "        else:\n",
    "            epi_img = nib.load(All_directory + filename)\n",
    "            x = epi_img.get_fdata()\n",
    "            x = (x-x.min())/x.max()\n",
    "            \n",
    "            x = np.expand_dims(x, axis=3)\n",
    "            X[objindex] = x\n",
    "            y = 0\n",
    "            if filename in AD_list:\n",
    "                y = 1\n",
    "                \n",
    "            Y[objindex] = y\n",
    "            \n",
    "            objindex += 1\n",
    "            \n",
    "    return X, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_dataset_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X[0:70]\n",
    "train_labels = Y[0:70]\n",
    "val_data = X[70:111] \n",
    "val_labels = Y[70:111] \n",
    "\n",
    "#test_data = X[205:245]\n",
    "#test_labels = Y[205:245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 110, 110, 110, 1)\n",
      "(70,)\n"
     ]
    }
   ],
   "source": [
    "print (train_data.shape)\n",
    "print (train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds keras 3D CNN model\n",
    "def build_cnn(dimension = '3d', activation = 'softmax', heatmap = False, w_path = None, compile_model = True):\n",
    "    input_3d = (img_size_x, img_size_y, img_size_z, 1)\n",
    "    \n",
    "    #VoxCNN architecture\n",
    "    \n",
    "    model = Sequential()\n",
    "    # 1st Volumetric Convolutional block\n",
    "    model.add(Conv3D(8, (3, 3, 3), activation='relu', padding='same', input_shape=input_3d))\n",
    "    model.add(Conv3D(8, (3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    # 2nd Volumetric Convolutional block\n",
    "    model.add(Conv3D(16, (3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv3D(16, (3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    # 3rd Volumetric Convolutional block\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    # 4th Volumetric Convolutional block\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Flatten())\n",
    "    # 1th Deconvolutional layer with batchnorm and dropout for regularization\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    # 2th Deconvolutional layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.5))\n",
    "    # Output with softmax nonlinearity for classification\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if w_path:\n",
    "        model.load_weights(w_path)\n",
    "    \n",
    "    opt = keras.optimizers.Adam(lr)\n",
    "    \n",
    "    if(compile_model):\n",
    "        model.compile(optimizer=opt,loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    print ('Done building model.')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1205 23:42:25.706437 139938613438208 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1205 23:42:25.726871 139938613438208 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1205 23:42:25.729829 139938613438208 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1205 23:42:25.963421 139938613438208 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1205 23:42:25.988982 139938613438208 deprecation.py:506] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1205 23:42:26.043478 139938613438208 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1205 23:42:26.049332 139938613438208 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1205 23:42:26.054371 139938613438208 deprecation.py:323] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building model.\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn(dimension = '3d', compile_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 110, 110, 110, 8)  224       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 110, 110, 110, 8)  1736      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 55, 55, 55, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 55, 55, 55, 16)    3472      \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 55, 55, 55, 16)    6928      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 27, 27, 27, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 27, 27, 27, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 27, 27, 27, 32)    27680     \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 27, 27, 27, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 13, 13, 13, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 13, 13, 13, 64)    55360     \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 13, 13, 13, 64)    110656    \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 13, 13, 13, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 6, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1769600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,136,681\n",
      "Trainable params: 2,136,425\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "roc_val_scores = []\n",
    "\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        roc_val_scores.append(round(roc_val,4))\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model architecture to data, also runs loss/accuracy tracker\n",
    "def fit_model(model, v, train_data, train_labels, val_data, val_labels):\n",
    "    roc_val_scores = []\n",
    "    model_weights_file = 'img_classifier_weights_%s.h5' %v\n",
    "    epoch_weights_file = 'img_classifier_weights_%s_{epoch:02d}_{val_acc:.2f}.hdf5' %v\n",
    "    model_file = 'img_classifier_model_%s.h5' %v\n",
    "    history_file = 'img_classifier_history_%s.json' %v\n",
    "    \n",
    "    def save_model_and_weights():\n",
    "        model.save(model_file)\n",
    "        model.save_weights(model_weights_file)\n",
    "        \n",
    "        return 'Saved model and weights to disk!'\n",
    "\n",
    "    def save_model_history(m):\n",
    "        with open(history_file, 'w', encoding=\"utf8\") as history_json_file:\n",
    "            json.dump(m.history, history_json_file)\n",
    "        \n",
    "        return 'Saved model history to disk!'\n",
    "    \n",
    "    def visualise_accuracy(m):\n",
    "        plt.plot(m.history['acc'])\n",
    "        plt.plot(m.history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "      \n",
    "    def visualise_loss(m):\n",
    "        plt.plot(m.history['loss'])\n",
    "        plt.plot(m.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.ylim(0,1.5)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "    \n",
    "    def model_callbacks():\n",
    "        checkpoint = ModelCheckpoint(epoch_weights_file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=early_stopping_patience, verbose=1, mode='auto')\n",
    "        \n",
    "        roc = roc_callback(training_data=(train_data, train_labels),validation_data=(val_data,val_labels))\n",
    "        \n",
    "        return [checkpoint, roc]\n",
    "        \n",
    "    callbacks_list = model_callbacks()\n",
    "    \n",
    "    y_ints = [y.argmax() for y in train_labels]\n",
    "    \n",
    "    #class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 #np.unique(y_ints),\n",
    "                                                 #y_ints)\n",
    "    #print (class_weights)\n",
    "    \n",
    "    m = model.fit(train_data,train_labels,batch_size=batch_size, epochs=epochs, verbose=1,shuffle=True,validation_data=(val_data,val_labels),callbacks=callbacks_list)\n",
    "    \n",
    "    print (save_model_and_weights())\n",
    "    print (save_model_history(m))\n",
    "    \n",
    "    visualise_accuracy(m)\n",
    "    visualise_loss(m)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 110, 110, 110, 1)\n",
      "(70,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples, validate on 41 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[10,110,110,110,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv3d_1/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics/acc/Mean_1/_301]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[10,110,110,110,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv3d_1/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8980e96b425a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-0f46b982fc3b>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, v, train_data, train_labels, val_data, val_labels)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#print (class_weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msave_model_and_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[10,110,110,110,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv3d_1/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics/acc/Mean_1/_301]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[10,110,110,110,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv3d_1/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "m = fit_model(model, \"v1\", train_data, train_labels, val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(m, weights, test_data, test_labels):    \n",
    "     \n",
    "    plt.close('all')\n",
    "\n",
    "    m.load_weights(weights)\n",
    "    m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print (\"Done compiling model.\")\n",
    "    \n",
    "    prediction = m.predict(test_data)\n",
    "    #prediction_labels = np_utils.to_categorical(np.argmax(prediction, axis=1), nb_classes)\n",
    "    \n",
    "    #print (prediction)\n",
    "    \n",
    "    pred = []\n",
    "    for p in prediction:\n",
    "        if float(p[0]) > 0.5:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    print (pred)\n",
    "    \n",
    "    print ('Accuracy on test data:', accuracy_score(test_labels, pred))\n",
    "\n",
    "    print ('Classification Report')\n",
    "    print (classification_report(test_labels, pred, target_names = ['NC', 'AD']))\n",
    "    \n",
    "    cm = confusion_matrix(test_labels,  pred)\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done compiling model.\n",
      "[1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "Accuracy on test data: 0.7560975609756098\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NC       0.84      0.70      0.76        23\n",
      "          AD       0.68      0.83      0.75        18\n",
      "\n",
      "    accuracy                           0.76        41\n",
      "   macro avg       0.76      0.76      0.76        41\n",
      "weighted avg       0.77      0.76      0.76        41\n",
      "\n",
      "[[16  7]\n",
      " [ 3 15]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(model, 'img_classifier_weights_v1.h5', val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5459, 0.5483, 0.5507, 0.5507, 0.5676, 0.5966, 0.6184, 0.5918, 0.57, 0.5604, 0.5556, 0.5628, 0.5652, 0.5652, 0.5604, 0.5676, 0.5749, 0.5749, 0.5725, 0.5749, 0.5821, 0.587, 0.587, 0.5918, 0.6039, 0.6329, 0.6353, 0.6304, 0.6594, 0.6546, 0.6546, 0.6884, 0.686, 0.657, 0.686, 0.7101, 0.6932, 0.7295, 0.7367, 0.7415, 0.7681, 0.7874, 0.7826, 0.7729, 0.7585, 0.7778, 0.7681, 0.7585, 0.8019, 0.7899]\n"
     ]
    }
   ],
   "source": [
    "print (roc_val_scores[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(roc_val_scores[50:100])\n",
    "plt.title('Validation ROC AUC')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
